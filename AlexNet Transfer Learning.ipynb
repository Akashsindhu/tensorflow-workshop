{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding in our own transfer layer by hand with AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in our previous exported model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    importer = tf.train.import_meta_graph('saved_models/alex_vars.meta')\n",
    "\n",
    "sess = tf.Session(graph=graph)\n",
    "importer.restore(sess, 'saved_models/alex_vars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get handle to second-to-last layer in pre-built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc7_op = graph.get_operation_by_name('fc7/relu')\n",
    "fc7 = fc7_op.outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc7.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new layer, attached to `fc7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create new final layer\n",
    "with graph.as_default():\n",
    "    x = graph.get_operation_by_name('input').outputs[0]\n",
    "    \n",
    "    with tf.name_scope('transfer'):\n",
    "        labels = tf.placeholder(tf.int32, [None])\n",
    "        one_hot_labels = tf.one_hot(labels, 2)\n",
    "\n",
    "        with tf.name_scope('cat_dog_final_layer'):\n",
    "            weights = tf.Variable(tf.truncated_normal([4096, 2], stddev=0.001),\n",
    "                                  name='final_weights')\n",
    "            biases = tf.Variable(tf.zeros([2]), name='final_biases')\n",
    "            logits = tf.nn.xw_plus_b(fc7, weights, biases, name='logits')\n",
    "\n",
    "        prediction = tf.nn.softmax(logits, name='cat_dog_softmax')\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_labels)\n",
    "        loss = tf.reduce_mean(cross_entropy, name='cat_dog_loss')\n",
    "\n",
    "        global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "        inc_step = global_step.assign_add(1)\n",
    "\n",
    "        cat_dog_variables = [weights, biases]\n",
    "        train = tf.train.GradientDescentOptimizer(0.01).minimize(loss, global_step=global_step,\n",
    "                                                                var_list=cat_dog_variables) \n",
    "    \n",
    "    with tf.name_scope('accuracy'):\n",
    "        label_prediction = tf.argmax(prediction, 1, name='predicted_label')\n",
    "        correct_prediction = tf.equal(label_prediction, tf.argmax(one_hot_labels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    \n",
    "    init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(graph=graph)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get our training file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_files = [\n",
    "    'data/dogs_and_cats/cats/' + f\n",
    "    for \n",
    "    f\n",
    "    in\n",
    "    os.listdir('data/dogs_and_cats/cats')\n",
    "]\n",
    "\n",
    "dog_files = [\n",
    "    'data/dogs_and_cats/dogs/' + f\n",
    "    for \n",
    "    f\n",
    "    in\n",
    "    os.listdir('data/dogs_and_cats/dogs')\n",
    "]\n",
    "\n",
    "all_files = cat_files + dog_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle and split into training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_files = len(all_files)\n",
    "valid_percentage = 0.3\n",
    "split = int(num_files * valid_percentage)\n",
    "valid_data = all_files[:split]\n",
    "train_data = all_files[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Number of training images: {}'.format(len(train_data)))\n",
    "print('Number of validation images: {}'.format(len(valid_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create generator to give us batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flip_left_right = True\n",
    "random_crop = 1\n",
    "random_scale = 1\n",
    "random_brightness = 1\n",
    "num_channels = 3\n",
    "height = 227\n",
    "width = 227\n",
    "pixel_depth = 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ntpath\n",
    "\n",
    "def get_batch(batch_size, data, max_epochs, should_distort=False):\n",
    "    distort_graph = tf.Graph()\n",
    "    with distort_graph.as_default():\n",
    "        \"\"\"\n",
    "        From https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py\n",
    "        \"\"\"\n",
    "        jpeg_name = tf.placeholder(tf.string, name='DistortJPGInput')\n",
    "        jpeg_data = tf.read_file(jpeg_name)\n",
    "        decoded_image = tf.image.decode_jpeg(jpeg_data, channels=3)\n",
    "        resized_image = tf.image.resize_images(decoded_image, height, width)\n",
    "        decoded_image_as_float = tf.cast(decoded_image, dtype=tf.float32)\n",
    "        decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\n",
    "        margin_scale = 1.0 + (random_crop / 100.0)\n",
    "        resize_scale = 1.0 + (random_scale / 100.0)\n",
    "        margin_scale_value = tf.constant(margin_scale)\n",
    "        resize_scale_value = tf.random_uniform(tf.python.framework.tensor_shape.scalar(),\n",
    "                                             minval=1.0,\n",
    "                                             maxval=resize_scale)\n",
    "        scale_value = tf.mul(margin_scale_value, resize_scale_value)\n",
    "        precrop_width = tf.mul(scale_value, width)\n",
    "        precrop_height = tf.mul(scale_value, width)\n",
    "        precrop_shape = tf.pack([precrop_height, precrop_width])\n",
    "        precrop_shape_as_int = tf.cast(precrop_shape, dtype=tf.int32)\n",
    "        precropped_image = tf.image.resize_bilinear(decoded_image_4d,\n",
    "                                                  precrop_shape_as_int)\n",
    "        precropped_image_3d = tf.squeeze(precropped_image, squeeze_dims=[0])\n",
    "        cropped_image = tf.random_crop(precropped_image_3d,\n",
    "                                     [width, width,\n",
    "                                      num_channels])\n",
    "        if flip_left_right:\n",
    "            flipped_image = tf.image.random_flip_left_right(cropped_image)\n",
    "        else:\n",
    "            flipped_image = cropped_image\n",
    "        brightness_min = 1.0 - (random_brightness / 100.0)\n",
    "        brightness_max = 1.0 + (random_brightness / 100.0)\n",
    "        brightness_value = tf.random_uniform(tf.python.framework.tensor_shape.scalar(),\n",
    "                                           minval=brightness_min,\n",
    "                                           maxval=brightness_max)\n",
    "        brightened_image = tf.mul(flipped_image, brightness_value)\n",
    "        distort_result = tf.expand_dims(brightened_image, 0, name='DistortResult')\n",
    "\n",
    "    distort_sess = tf.Session(graph=distort_graph)\n",
    "    \n",
    "    epoch = 0\n",
    "    idx = 0\n",
    "    while epoch < max_epochs: \n",
    "        batch = []\n",
    "        labels = []\n",
    "        for i in range(batch_size):\n",
    "            if idx + i >= len(data):\n",
    "                random.shuffle(data)\n",
    "                epoch += 1\n",
    "                idx = 0\n",
    "            image_path = data[idx + i].encode()\n",
    "            if should_distort:\n",
    "                val = distort_sess.run(distort_result, \n",
    "                                       feed_dict={jpeg_name: image_path})\n",
    "            else:\n",
    "                val = distort_sess.run(resized_image, \n",
    "                                       feed_dict={jpeg_name: image_path})\n",
    "            if b'dog' in ntpath.basename(image_path):\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "            batch.append(val)\n",
    "        idx += batch_size\n",
    "        yield batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick save of our model to view later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = tf.train.SummaryWriter('tensorboard/alexnet_retrain', graph=graph)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data_batch, label_batch in get_batch(32, train_data, 1, should_distort=True):\n",
    "    data_batch = np.squeeze(data_batch)\n",
    "    feed_dict = {x: data_batch, labels: label_batch}\n",
    "    err, acc, step, _ = sess.run([loss, accuracy, inc_step, train],\n",
    "                            feed_dict=feed_dict)\n",
    "    if step % 50 == 0:\n",
    "        print(\"Step: {}\\t Accuracy: {}\\t Error: {}\".format(step, acc, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_accuracy(valid_data):\n",
    "    batch_size = 50\n",
    "    num_correct = 0\n",
    "    total = len(valid_data)\n",
    "    i = 0\n",
    "    for data_batch, label_batch in get_batch(batch_size, valid_data, 1):\n",
    "        feed_dict = {x: data_batch, labels: label_batch}\n",
    "        correct_guesses = sess.run(correct_prediction,\n",
    "                                   feed_dict=feed_dict)\n",
    "        num_correct += np.sum(correct_guesses)\n",
    "        i += batch_size\n",
    "        if i % (batch_size * 10) == 0:\n",
    "            print('\\tIntermediate accuracy: {}'.format((float(num_correct) / float(i))))\n",
    "    acc = num_correct / float(total)\n",
    "    print('\\nAccuracy: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_accuracy(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once again, let's inspect for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def spot_check():\n",
    "    filename = random.choice(valid_data)\n",
    "    image = ndimage.imread(filename)\n",
    "    feed_dict = {x: [image]}\n",
    "    guess = sess.run(label_prediction, feed_dict=feed_dict)\n",
    "    if guess[0] == 1:\n",
    "        print('Guess: dog')\n",
    "    else:\n",
    "        print('Guess: cat')\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spot_check()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
